{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166f5e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat:93803acf-5964-4de1-be48-68781031d071\n",
      "[{'role': 'user', 'content': 'What is Transformers?'}, {'role': 'assistant', 'content': 'Answer:\\nTransformers are a type of artificial intelligence model—a neural network that learns the context of sequential data and generates new data from it.  They were originally created to solve sequence‑transduction problems such as neural machine translation, enabling any task that transforms an input sequence into an output sequence.  Today they are considered a state‑of‑the‑art NLP model for understanding and generating human‑like text by analyzing patterns in large amounts of text data.\\n\\nSources:\\n- sample.pdf (page 2)'}, {'role': 'user', 'content': 'Explain it in simpler terms.'}, {'role': 'assistant', 'content': 'Answer:\\nTransformers are a kind of AI model that reads a whole sentence (or any list of items) all at once instead of one word at a time.  \\nThey look at every word and decide, using a special “attention” trick, which other words matter most for understanding or predicting the next word.  \\nBecause they don’t have to wait for each word to finish, they can learn patterns in language much faster and more accurately than older models that read words one after another.\\n\\nSources:\\n- sample.pdf (page 3)'}]\n",
      "chat:78f7c7bc-0a91-4f75-968d-f69d9049b746\n",
      "[{'role': 'user', 'content': 'Explain it in simpler terms.'}, {'role': 'assistant', 'content': 'Answer:\\nRNNs (like LSTM) were the go‑to way to handle data that comes in a sequence, such as sentences. They work like a chain: each word is fed in one after another, and the network keeps a memory of what it has seen so far. This makes them slow and sometimes hard to train.\\n\\nTransformers replaced that chain‑like approach. Instead of passing information step by step, a Transformer looks at the whole sequence at once and uses a special “attention” trick to figure out which parts of the input are most important for each output. This lets it learn relationships between words (or other elements) more efficiently and with less computational cost.\\n\\nIn short, Transformers moved from a slow, step‑by‑step method (RNNs) to a fast, all‑at‑once method that focuses on the most relevant parts of the data (attention).\\n\\nSources:\\n- sample.pdf (page 3)'}]\n",
      "chat:cb1ba384-5103-4718-97a6-66fc2399c8de\n",
      "[{'role': 'user', 'content': 'what is Transformers?'}, {'role': 'assistant', 'content': 'Answer:\\nTransformers are a type of artificial‑intelligence model—a neural network that learns the context of sequential data and can generate new data from it.  They were originally created to solve sequence‑transduction problems such as neural machine translation, meaning they can transform any input sequence into an output sequence.  Today they are the state‑of‑the‑art model for natural‑language processing, capable of understanding and producing human‑like text by analyzing patterns in large amounts of text data.\\n\\nSources:\\n- sample.pdf (page 2)'}, {'role': 'user', 'content': 'What is this document about?'}, {'role': 'assistant', 'content': 'Answer:\\nThe document discusses the evolution of neural‑network models for natural‑language processing, focusing on the transition from recurrent neural networks (RNNs) such as LSTMs to the Transformer architecture. It explains how Transformers were inspired by the encoder‑decoder design of RNNs but replace recurrence with a pure attention mechanism, highlighting the shift in approach and the new capabilities this brings to NLP tasks.\\n\\nSources:\\n- sample.pdf (page 3)'}, {'role': 'user', 'content': 'Explain it in simpler terms.'}, {'role': 'assistant', 'content': 'Answer:\\nTransformers are a newer way to process sequences of data (like sentences) that doesn’t read the data one piece at a time.  \\nInstead of going step‑by‑step like older models (RNNs), Transformers look at the whole sequence all at once and use a special “attention” trick to figure out which parts of the sequence are most important for each other.  \\nThis lets them learn patterns faster and handle longer sentences better.\\n\\nSources:\\n- sample.pdf (page 3)'}]\n",
      "chat:c9c679ab-4bb9-4817-8f3d-e71fe97acb20\n",
      "[{'role': 'user', 'content': 'Explain it in simpler terms.'}, {'role': 'assistant', 'content': 'Answer:\\nRNNs (like LSTM) were the go‑to way to handle data that comes in a sequence, such as sentences. They work by looking at one piece of the sequence at a time, feeding the result forward to the next step, just like a chain of linked boxes.  \\nTransformers replaced this step‑by‑step approach. Instead of waiting for each piece to finish before moving on, a Transformer looks at the whole sequence all at once and uses a special “attention” trick to figure out which parts of the sequence are most important for each other. This lets it process data much faster and often more accurately.\\n\\nSources:\\n- sample.pdf (page 3)'}, {'role': 'user', 'content': 'W'}, {'role': 'assistant', 'content': \"I don't know based on the provided documents.\"}, {'role': 'user', 'content': 'What did I ask before?'}, {'role': 'assistant', 'content': 'Answer:\\nYou previously asked: “Explain it in simpler terms.”\\n\\nSources:\\n- conversation (page 1)'}]\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "import json\n",
    "\n",
    "r = redis.from_url(\"redis://localhost:6379\", decode_responses=True)\n",
    "\n",
    "for key in r.keys(\"chat:*\"):\n",
    "    print(key)\n",
    "    print(json.loads(r.get(key)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
